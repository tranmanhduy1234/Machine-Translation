# MÃ´ hÃ¬nh dá»‹ch mÃ¡y tá»± xÃ¢y dá»±ng Transformer2025
## ğŸ“‹ MÃ´ táº£ dá»± Ã¡n
âœ¨ Kiáº¿n trÃºc gá»‘c: Transformer 2017  
âœ¨ XÃ¢y dá»±ng: Tráº§n Máº¡nh Duy
## ğŸš€Nhá»¯ng ká»¹ thuáº­t má»›i Ä‘Æ°á»£c sá»­ dá»¥ng so vá»›i kiáº¿n trÃºc gá»‘c trong bÃ i bÃ¡o Attention is all you need
- Pre-norm Ä‘Æ°á»£c sá»­ dá»¥ng thay cho post-norm truyá»n thá»‘ng
- FlashAttention, gom ma tráº­n tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½
- Embedding learnable
- Khá»Ÿi táº¡o trá»ng sá»‘ ban Ä‘áº§u xavier
- Thay Ä‘á»•i hÃ m kÃ­ch hoáº¡t á»Ÿ FFN sang switch (SILU) - thay vÃ¬ RELU

## ğŸ”§CÃ¡c váº¥n Ä‘á» trong quÃ¡ trÃ¬nh xÃ¢y dá»±ng
- XÃ¢y dá»±ng kiáº¿n trÃºc Transformer âœ…
- XÃ¢y dá»±ng head predict sá»­ dá»¥ng beemsearch âœ…
- Feature Engineering & Preprocessing
- Data cleaning: remove NaN, handle outliers
- Normaiization/Standaridization
- Dataloader xá»­ lÃ½, gom dá»¯ liá»‡u trÆ°á»›c khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh.
- Loss Function vÃ  Optimizer
- Training code Forward Pass / Backward Pass - Gradient Descent - Epoch / Batch / Iteration - Backpropagation - Regularization: L1, L2, Dropout - Early Stopping
- Validation & Hyperparameter Tuning
- Search Methods: Grid Search, Random Search, Bayesian Optimization
- CÃ³ thá»ƒ trá»«ng pháº¡t trá»ng sá»‘ riÃªng cho tá»«ng lá»›p
- Train
- Evaluation
- Monitoring & Inference
- CÃ¢n nháº¯c chuyá»ƒn Ä‘á»•i LayerNorm qua RMSNorm